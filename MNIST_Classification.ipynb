{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass Classification using MNIST Dataset"
      ],
      "metadata": {
        "id": "aEBHOpZXqFcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ],
      "metadata": {
        "id": "7-3i0YtpqRza"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T60KX4t3_wHK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from time import time\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Random seed"
      ],
      "metadata": {
        "id": "iap_KV18qbRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "BCsbDBecBRAb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set device"
      ],
      "metadata": {
        "id": "VwcZ_T9VxCzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "metadata": {
        "id": "LmKU0t27xAuV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arguments regarding data, model and training"
      ],
      "metadata": {
        "id": "LjckkoC-vATJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 512\n",
        "epochs = 25\n",
        "iters = 150\n",
        "learning_rate = 0.001\n",
        "# Minibatch size\n",
        "bsz = 128\n",
        "device = set_device()"
      ],
      "metadata": {
        "id": "TMLJAMmUBT3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427e2077-3321-4a90-8ced-a924d4d18c0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is enabled in this notebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download MNIST Data"
      ],
      "metadata": {
        "id": "QYbSwZvIq3UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_data(frac=False):\n",
        "  idx = np.arange(60000)\n",
        "  np.random.shuffle(idx)\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  X_train = np.reshape(x_train, [-1, 784])\n",
        "  X_test = np.reshape(x_test, [-1, 784])\n",
        "\n",
        "  if frac:\n",
        "    return X_train[idx[:10000], :128], y_train[idx[:10000]], X_test[:, 128], y_test, 10, 128\n",
        "  else:\n",
        "    return X_train, y_train, X_test, y_test, 10, 784"
      ],
      "metadata": {
        "id": "AAwDvqBdFaUA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val, nc, d = mnist_data()\n",
        "\n",
        "X_train = torch.Tensor(X_train)\n",
        "y_train = torch.Tensor(y_train)\n",
        "X_val = torch.Tensor(X_val)\n",
        "y_val = torch.Tensor(y_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9XKsHyTqhb1",
        "outputId": "cb540cad-c612-419f-e207-31c2b9bb2406"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "torch.Size([60000, 784])\n",
            "torch.Size([60000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Data"
      ],
      "metadata": {
        "id": "Fy_uWBs3tQrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_figures = 3\n",
        "fig, axs = plt.subplots(1, num_figures, figsize=(5 * num_figures, 5))\n",
        "\n",
        "for sample_id, ax in enumerate(axs):\n",
        "  # Plot the pixel values for each image\n",
        "  ax.matshow(X_train[sample_id, :].reshape(28,28), cmap='gray')\n",
        "\n",
        "  ax.set_title('Label: ' + str(y_train[sample_id].long().item()))\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "WF253d6u609g",
        "outputId": "8d516867-dead-4ef5-ce95-aa8a031f9e78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAEgCAYAAABRkSnaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUfUlEQVR4nO3df6zdZX0H8M9TahFkLYM5cLIiLqUElvZKLSIzFC2oUwhCAdMAHZkrJEjWGNdlmqJ1DvzVmln8RWSglCawjBUqiEhWqItC11rpJhWsulGLF4VKoS0Ig373x223ytrzHD/39J577n29kpvc5nn3OZ8D7dO+7/c2T2maJgAAAPjtjOn2AAAAAL1ImQIAAEhQpgAAABKUKQAAgARlCgAAIEGZAgAASFCmRoFSyn2llL8Y6p8LUON8AoYjZxPtUqZ6SCnlv0opp3d7jn0ppVxSSnmplLJ9j4/Tuj0XsP8N9/MpIqKU8oFSyuOllGdKKdeXUg7s9kzA/tULZ9NupZR/KaU0pZSx3Z6F9ilTdNr9TdMcssfHfd0eCKCU8o6I+JuImBkRR0fE6yPiY10dCmCXUsqFEfGKbs/Bb0+ZGgFKKb9bSrmjlPJEKeWpXZ8f9bLYH5VS/m3XV2RvL6UctsfPP7mU8t1SytZSynpPk4BOGUbn059FxD80TfNQ0zRPRcTHI+KS5F5AjxtGZ1OUUiZExEcj4q+ze9A9ytTIMCYiboiBr7ZOjIjnIuLzL8vMiYg/j4jXRMSLEbEkIqKU8tqIuDMi/i4iDouIv4qIW0spr375i5RSJu46NCa2mOUNpZQnSyk/KqVc6VE1jHrD5Xw6ISLW7/Hj9RFxRCnl8OT7AnrbcDmbIiKujogvRcTjg3lDdIcyNQI0TbOlaZpbm6Z5tmmabRFxVUTMeFlsadM0P2iaZkdEXBkRF5RSDoiIiyLiG03TfKNpmp1N09wTEWsj4l17eZ1NTdMc2jTNpn2M8u2I+OOI+P2ImBURsyNifkfeJNCThtH5dEhEPL3Hj3d//juDeHtAjxouZ1Mp5Y0R8ScRcU0H3x5DSJkaAUopB5dSri2lPFpKeSYGSs2hu37D7/azPT5/NAa+L/f3YuArMufv+qrJ1lLK1oh4Swx8Fea30jTNT5um+c9dB8t/RMTfRsR52fcF9L7hcj5FxPaIGL/Hj3d/vi2xF9DjhsPZVEoZExFfjIh5TdO8OJj3Q/f4FqyR4YMRMTki3tQ0zeOllL6I+H5ElD0yf7jH5xMj4r8j4skYOCiWNk0zdz/M1bxsBmD0GS7n00MRMTUi/nHXj6dGxC+aptnSgb2B3jMczqbxEfHGiLillBIRsbvIbS6lnN80zb8Ocn+GgCdTvecVpZRX7vExNga+TeW5iNi66x9HfnQvP++iUsrxpZSDY+CJ0T81TfNSRNwUEWeVUt5RSjlg156n7eUfYVaVUv60lHLErs+Pi4FH4rcn3yfQe4bt+RQRN0bE+3a9zqERsSAivpp5k0DPGa5n09MR8QcR0bfrY/e3CU6LiNW//dukG5Sp3vONGPjNv/tjYUT8fUQcFANfLXkgIr65l5+3NAb+4vB4RLwyIv4yIqJpmp9FxNkR8eGIeCIGvtoyP/bya2PXP6Lc3uIfUc6MiH8vpezYNec/x8A/qgRGh2F7PjVN882I+HRE3BsRm2LgW3b29pcnYOQZlmdTM+Dx3R+79ooYeGr+QvbNMrRK0zTdngEAAKDneDIFAACQoEwBAAAkKFMAAAAJyhQAAECCMgUAAJCgTAEAACQoUwAAAAnKFAAAQIIyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCMgUAAJAwttViKaUZqkGAodM0Ten2DIPlfIKRqdfPJ2cTjEz7Ops8mQIAAEhQpgAAABKUKQAAgARlCgAAIEGZAgAASFCmAAAAEpQpAACABGUKAAAgQZkCAABIUKYAAAASlCkAAIAEZQoAACBBmQIAAEhQpgAAABKUKQAAgARlCgAAIEGZAgAASFCmAAAAEpQpAACABGUKAAAgQZkCAABIUKYAAAASlCkAAIAEZQoAACBBmQIAAEhQpgAAABKUKQAAgARlCgAAIEGZAgAASFCmAAAAEpQpAACABGUKAAAgQZkCAABIGNvtAQBgsKZNm1bNXHHFFdXMnDlzqpkbb7yxmrnmmmtarq9bt666BwDDnydTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCMgUAAJCgTAEAACSUpmn2vVjKvhcZNg444IBqZsKECUMwSXuXYh588MHVzOTJk6uZ97///S3XFy1aVN1j9uzZ1cyvf/3rauaTn/xkNfOxj32smhkqTdOUbs8wWM6n0aOvr6+aWblyZTUzfvz4TozTlqeffrrl+uGHHz5Ek/SeXj+fnE30spkzZ1Yzy5Ytq2ZmzJhRzTzyyCNtzTRc7Ots8mQKAAAgQZkCAABIUKYAAAASlCkAAIAEZQoAACBBmQIAAEhQpgAAABKUKQAAgISx3R6gV02cOLHl+rhx46p7nHLKKdXMW97ylmrm0EMPrWZmzZpVzQwnmzdvrmaWLFnScv2cc86p7rFt27ZqZv369dXMqlWrqhlg70466aSW67feemt1j3YuJm91Sf1u7ZwJL7zwQjVTu5T35JNPru6xbt26jszC6HXqqadWM+1cIL18+fJOjEMPmD59ejWzZs2aIZikd3gyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCS3v3oq+vr5pZuXJly/V2LpAcrXbu3FnNLFiwoJrZvn17y/Vly5ZV9+jv769mnnrqqWrmkUceqWZgpDn44IOrmRNPPLGauemmm1quv+Y1r2l7psHauHFjNfPpT3+6mrn55ptbrn/nO9+p7tHOOfiJT3yimmH0Ou2006qZSZMmVTMu7R05xoxp/RzlmGOOqe5x9NFHVzOllLZn6nWeTAEAACQoUwAAAAnKFAAAQIIyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQ4NLevdi0aVM1s2XLlpbrvXZp7+rVq6uZrVu3VjNvfetbq5kXXnihmlm6dGk1A3TXtddeW83Mnj17CCbpnHYuGT7kkEOqmVWrVrVcb+cy1SlTplQz0MqcOXOqmfvvv38IJmG4qF2CPnfu3OoetYvWIyIefvjhtmfqdZ5MAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCe6b24le/+lU1M3/+/JbrZ555ZnWP73//+9XMkiVLqpl2PPjggy3XzzjjjOoeO3bsqGZOOOGEambevHnVDNBd06ZNq2be/e53VzOllEHPUruzKSLi61//ejWzaNGiaubnP/95NdPO2f3UU0+1XH/b295W3aMT/+0Y3caM8TVzftN111036D02btzYgUlGDr/LAAAAEpQpAACABGUKAAAgQZkCAABIUKYAAAASlCkAAIAEZQoAACBBmQIAAEhwaW/Sbbfd1nJ95cqV1T22bdtWzUydOrWaed/73lfN1C6rbOdC3nY89NBD1cyll17akdcCcvr6+qqZe+65p5oZP358NdM0TTVz1113tVyfPXt2dY8ZM2ZUMwsWLKhm2rnQ8oknnqhm1q9f33J9586d1T3auRT5xBNPrGbWrVtXzdB7pkyZUs0cccQRQzAJvWTChAmD3qOdPx9GE0+mAAAAEpQpAACABGUKAAAgQZkCAABIUKYAAAASlCkAAIAEZQoAACBBmQIAAEhwae9+8swzz3Rkn6effroj+8ydO7fl+i233FLdo51LJoHuO/bYY1uuz58/v7pHOxc7Pvnkk9VMf39/NfO1r32t5fr27dure9x5550dyQwnBx10UDXzwQ9+sJq58MILOzEOw8y73vWuaqadX0OMHO1c0nzMMccM+nUee+yxQe8xkngyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCS3uHuYULF1Yz06ZNq2ZmzJjRcv3000+v7vGtb32rmgH2rwMPPLCaWbRoUcv1di773LZtWzUzZ86cambt2rXVjItF8yZOnNjtEeiSyZMnd2Sfhx56qCP70H21sz+ifrHvj370o+oe7fz5MJp4MgUAAJCgTAEAACQoUwAAAAnKFAAAQIIyBQAAkKBMAQAAJChTAAAACcoUAABAgkt7h7kdO3ZUM3Pnzq1m1q1b13L9K1/5SnWPe++9t5pp54LOL3zhC9VM0zTVDIxGb3jDG6qZdi7lrTn77LOrmVWrVg36dYDuWrNmTbdHGNHGjx9fzbzzne+sZi666KJq5u1vf3tbM7Xy8Y9/vJrZunXroF9nJPFkCgAAIEGZAgAASFCmAAAAEpQpAACABGUKAAAgQZkCAABIUKYAAAAS3DM1AvzkJz+pZi655JKW6zfccEN1j4svvrgjmVe96lXVzI033ljN9Pf3VzMw0nz2s5+tZkopLdfbuR/KHVL715gx9a9l7ty5cwgmYbQ77LDDuj3C/5o6dWo1UzvfIiJOP/30auaoo46qZsaNG9dy/cILL6zu0c7v9eeee66aWb16dTXz/PPPVzNjx7b+q//3vve96h78Jk+mAAAAEpQpAACABGUKAAAgQZkCAABIUKYAAAASlCkAAIAEZQoAACBBmQIAAEhwae8osXz58pbrGzdurO7RzmWhM2fOrGauvvrqauboo4+uZq666qqW64899lh1DxhOzjzzzGqmr6+vmmmapuX6ihUr2p6J/aOdC3lr/x8jIh588MFOjEMPauei13Z+DX35y1+uZj784Q+3NdNgTZkypZpp59LeF198sZp59tlnq5kNGza0XL/++uure6xdu7aaaeeS9F/84hfVzObNm6uZgw46qOX6ww8/XN2D3+TJFAAAQIIyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJLu0lIiJ+8IMfVDMXXHBBNXPWWWdVMzfccEM1c9lll1UzkyZNarl+xhlnVPeA4aR2mWJExLhx46qZX/7yly3Xb7nllrZn4v878MADq5mFCxcO+nVWrlxZzXzoQx8a9OvQmy6//PJq5tFHH61mTjnllE6M0xGbNm2qZm677bZq5oc//GE188ADD7Q103Bx6aWXVjOvfvWrq5mf/vSnnRiHPXgyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCS3tp29atW6uZpUuXVjPXXXddNTN2bP2X5qmnntpy/bTTTqvucd9991Uz0Guef/75luv9/f1DNEnvaedC3gULFlQz8+fPb7m+efPm6h6LFy+uZrZv317NMHp96lOf6vYIdMjMmTM7ss+tt97akX34P55MAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCMgUAAJDg0l4iImLKlCnVzHnnnVfNTJ8+vZpp50LedmzYsKHl+re//e2OvA70mhUrVnR7hGGpr6+vmqldthsR8d73vreauf3221uuz5o1q7oHQKctX7682yOMOJ5MAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCMgUAAJDg0t4RYPLkydXMFVdc0XL93HPPre5x5JFHtj3TYL300kvVTH9/f8v1nTt3dmocGBKllI5k3vOe97RcnzdvXtsz9YoPfOAD1cyVV15ZzUyYMKGaWbZsWTUzZ86cagaA3ufJFAAAQIIyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkuGeqi9q5t2n27NnVTO0OqYiI173ude2MNCTWrl1bzVx11VXVzIoVKzoxDgwbTdN0JFM7W5YsWVLd4/rrr69mtmzZUs2cfPLJ1czFF1/ccn3q1KnVPY466qhqZtOmTdXM3XffXc188YtfrGYAhlo79xAee+yxLdcfeOCBTo0zangyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAECCS3uTjjjiiJbrxx9/fHWPz3/+89XMcccd1/ZM+9vq1aurmc985jPVzO23317N7Ny5s62ZgP/vgAMOaLl++eWXV/eYNWtWNfPMM89UM5MmTapmOuG73/1uNXPvvfdWMx/5yEc6MQ7AkGvnUvcxYzxH6TT/RQEAABKUKQAAgARlCgAAIEGZAgAASFCmAAAAEpQpAACABGUKAAAgQZkCAABIGHWX9h522GHVzLXXXlvN9PX1tVx//etf3/ZMQ6F2oeXixYure9x9993VzHPPPdf2TMBvuv/++6uZNWvWVDPTp08f9CxHHnlkNVO7vLxdW7Zsabl+8803V/eYN29eR2YBGMne/OY3t1z/6le/OjSDjCCeTAEAACQoUwAAAAnKFAAAQIIyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQ0DOX9r7pTW+qZubPn1/NnHTSSdXMa1/72rZmGgrPPvtsNbNkyZJq5uqrr265vmPHjrZnAvaPzZs3VzPnnntuNXPZZZe1XF+wYEHbMw3W5z73uWrmS1/6Usv1H//4x50aB2DEKqV0e4RRyZMpAACABGUKAAAgQZkCAABIUKYAAAASlCkAAIAEZQoAACBBmQIAAEhQpgAAABJ65tLec845pyOZTtmwYUPL9TvuuKO6x4svvljNLF68uJrZunVrNQOMDP39/dXMwoULB7UOwPBy1113VTPnn3/+EEzCy3kyBQAAkKBMAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJyhQAAEBCaZpm34ul7HsR6FlN05RuzzBYzicYmXr9fHI2wci0r7PJkykAAIAEZQoAACBBmQIAAEhQpgAAABKUKQAAgARlCgAAIEGZAgAASFCmAAAAEpQpAACABGUKAAAgQZkCAABIUKYAAAASlCkAAIAEZQoAACBBmQIAAEhQpgAAABKUKQAAgARlCgAAIEGZAgAASFCmAAAAEpQpAACABGUKAAAgQZkCAABIUKYAAAASlCkAAICE0jRNt2cAAADoOZ5MAQAAJChTAAAACcoUAABAgjIFAACQoEwBAAAkKFMAAAAJ/wMNDKoW+hu1YgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "6UeDihBXtel3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minibatch(X, y, num_points):\n",
        "  \"\"\"\n",
        "  Sample a minibatch of size num_point from the provided input-target data\n",
        "\n",
        "  Args:\n",
        "    X: Tensor\n",
        "      Multi-dimensional tensor containing the input data\n",
        "    y: Tensor\n",
        "      1D tensor containing the ground truth\n",
        "    num_points: Integer\n",
        "      Number of elements to be included in minibatch\n",
        "\n",
        "  Returns:\n",
        "    batch_x: Tensor\n",
        "      Minibatch inputs\n",
        "    batch_y: Tensor\n",
        "      Minibatch targets\n",
        "  \"\"\"\n",
        "  # Sample a collection of IID indices from the existing data\n",
        "  batch_indices = np.random.choice(len(X), num_points)\n",
        "  # Use batch_indices to extract entries from the input and target data tensors\n",
        "  batch_x = X[batch_indices]\n",
        "  batch_y = y[batch_indices]\n",
        "\n",
        "  return batch_x, batch_y"
      ],
      "metadata": {
        "id": "vRSIxyh4vhyF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(pred, y):\n",
        " \n",
        "  # Function to calculate the accuracy of model predictions\n",
        " \n",
        "  a = torch.eq(pred, y.long()).double().mean() * 100\n",
        "\n",
        "  return a"
      ],
      "metadata": {
        "id": "MA0oaIz5UoHV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification using MLP"
      ],
      "metadata": {
        "id": "XFdJTCaCtkBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  \"\"\"\n",
        "   A neural network with a single hidden layer\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    \"\"\"\n",
        "    Initializing the parameters of MLP\n",
        "\n",
        "    Args:\n",
        "      input_size: Int\n",
        "        Number of input features (784)\n",
        "      hidden_size: List\n",
        "        Containing the dimensions of the hidden layers\n",
        "      output_size: Int\n",
        "        Number of output classes (10)\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(MLP, self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(input_size, hidden_size[0]),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_size[0], hidden_size[1]),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_size[1], hidden_size[2]),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_size[2], output_size)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass\n",
        "\n",
        "    Args:\n",
        "      x: torch.Tensor\n",
        "        D-dimensional tensor of features\n",
        "\n",
        "    Returns:\n",
        "      Torch tensor of model predictions\n",
        "    \"\"\"\n",
        "\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "DoChXcVGESgj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance\n",
        "mlp = MLP(input_size = X_train.shape[1], hidden_size = [200, 100, 50], output_size = nc).to(device)\n",
        "# Adam optimizer\n",
        "adam_optimizer = torch.optim.Adam(mlp.parameters(), lr= learning_rate)\n",
        "# Create a cross entropy loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "lL-sEqfMQXT0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, model, criterion, optimizer, iters, bsz):\n",
        "  \"\"\"\n",
        "  Training function\n",
        "\n",
        "  Args:\n",
        "    X: torch.Tensor\n",
        "      Features (input) with shape torch.Size([N, d])\n",
        "    y: torch.Tensor\n",
        "      Labels (targets) with shape torch.Size([N, nc])\n",
        "    model: torch nn.Module\n",
        "      The neural network\n",
        "    criterion: function\n",
        "      Loss function\n",
        "    optimizer: function\n",
        "      Optimizer\n",
        "    iters: int\n",
        "      Number of training iterations\n",
        "    bsz: int\n",
        "      Number of elements in the minibatch\n",
        "\n",
        "  Returns:\n",
        "    avg_loss: float\n",
        "      Average loss over all iters\n",
        "    acc: float\n",
        "      Average training accuracy over all iters\n",
        "  \"\"\"\n",
        "  model.train()  \n",
        "  X = X.to(device)\n",
        "  y = y.to(device)\n",
        "\n",
        "  loss_record = [] # Keeping records of loss\n",
        "  acc_record = [] # Keeping records of accuracy\n",
        "  \n",
        "  for i in range(iters):\n",
        "    \n",
        "    # Extract minibatch data and labels\n",
        "    batch_X, batch_y = minibatch(X, y, bsz)\n",
        "    \n",
        "    # Reset all gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass (Compute the output of the model on the features (inputs))\n",
        "    y_pred = model(batch_X)\n",
        "    \n",
        "    # Compute the loss\n",
        "    loss = criterion(y_pred, batch_y.long())\n",
        "    \n",
        "    # Perform backpropagation and compute the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer takes a tiny step in the steepest direction (negative of gradient) and \"updates\" the weights and biases of the network\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_record.append(loss.item())\n",
        "    acc_record.append(accuracy(torch.argmax(y_pred, dim=1), batch_y).item())\n",
        "\n",
        "  # Compute average loss over all iterations\n",
        "  avg_loss = np.sum(loss_record) / iters\n",
        "  avg_acc = np.sum(acc_record) / iters\n",
        "\n",
        "  return avg_loss, avg_acc\n",
        "\n",
        "def eval(X, y, model, criterion):\n",
        "  \"\"\"\n",
        "  Function to gauge network performance\n",
        "\n",
        "  Args:\n",
        "    X: torch.tensor\n",
        "      Features (input) with shape torch.Size([N, d])\n",
        "    y: torch.tensor\n",
        "      Labels (targets) with shape torch.Size([N, nc])\n",
        "    model: torch nn.Module\n",
        "      The neural network\n",
        "    criterion: function\n",
        "      Loss function\n",
        "\n",
        "  Returns:\n",
        "    eval_loss: float \n",
        "      Scalar loss value over (X, y) using the model \n",
        "    eval_acc: float\n",
        "      Validation accuracy \n",
        "  \"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    y_pred = model(X)\n",
        "  \n",
        "    eval_loss = criterion(y_pred, y.long()).item()\n",
        "  \n",
        "    # Compute accuracy\n",
        "    eval_acc = accuracy(torch.argmax(y_pred,dim=1), y)\n",
        "\n",
        "  return eval_loss, eval_acc"
      ],
      "metadata": {
        "id": "97ks_dtaRYIc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(model, optimizer, criterion, epochs, iters, X_train, X_val, y_train, y_val, bsz):\n",
        "  \"\"\"\n",
        "  Train the model and tests the learned model\n",
        "    \n",
        "    Args:\n",
        "      model: torch nn.Module\n",
        "        The neural network\n",
        "      optimizer: function\n",
        "        optimizer\n",
        "      criterion: function\n",
        "        Loss function\n",
        "      epochs: int\n",
        "        number of training and validation iterations\n",
        "      iters: int\n",
        "        Number of training iterations\n",
        "      X_train: torch.Tensor\n",
        "        Training features (input) with shape torch.Size([N, d])\n",
        "      X_val: torch.Tensor\n",
        "        Validation features (input) with shape torch.Size([N, d])\n",
        "      y_train: torch.tensor\n",
        "        Training labels (targets) with shape torch.Size([N, 1])\n",
        "      y_val: torch.tensor\n",
        "        Validation labels (targets) with shape torch.Size([N, 1])\n",
        "      bsz: int\n",
        "        Number of elements in the minibatch\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "  \"\"\"\n",
        "  for i in range(epochs):\n",
        "    losses, train_acc = train(X_train, y_train, model, criterion, optimizer, iters, bsz)\n",
        "    val_loss, val_acc = eval(X_val, y_val, model, criterion)\n",
        "    if i % 5 == 0 or i == epochs - 1:\n",
        "      print(f'Epoch: {i} train loss: {losses:.2f} Validation loss: {val_loss:.2f} train accuracy: {train_acc:.2f} validation accuracy: {val_acc:.2f}')"
      ],
      "metadata": {
        "id": "HYUpQmQIYpaI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(mlp, adam_optimizer, criterion, epochs, iters, X_train, X_val, y_train, y_val, bsz)"
      ],
      "metadata": {
        "id": "Swr_XjnuyIQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a584915-c6de-460c-8e47-2aa00b03953a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 train loss: 0.47 Validation loss: 0.24 train accuracy: 87.01 validation accuracy: 93.12\n",
            "Epoch: 5 train loss: 0.10 Validation loss: 0.14 train accuracy: 96.96 validation accuracy: 96.07\n",
            "Epoch: 10 train loss: 0.07 Validation loss: 0.13 train accuracy: 97.88 validation accuracy: 96.28\n",
            "Epoch: 15 train loss: 0.05 Validation loss: 0.14 train accuracy: 98.18 validation accuracy: 96.47\n",
            "Epoch: 20 train loss: 0.05 Validation loss: 0.11 train accuracy: 98.61 validation accuracy: 97.17\n",
            "Epoch: 24 train loss: 0.04 Validation loss: 0.14 train accuracy: 98.64 validation accuracy: 96.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification using Logistic Regression"
      ],
      "metadata": {
        "id": "u_OA6f22twKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticReg(nn.Module):\n",
        " \n",
        "  # A single layer neural network\n",
        " \n",
        "  def __init__(self, input_size, output_size):\n",
        "\n",
        "    \"\"\"\n",
        "    Initializing the parameters of the network\n",
        "\n",
        "    Args:\n",
        "      input_size: Int\n",
        "        Number of input features\n",
        "      output_size: Int\n",
        "        Number of output features\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(LogisticReg, self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(input_size, output_size)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass\n",
        "\n",
        "    Args:\n",
        "      x: torch.Tensor\n",
        "        D-dimensional tensor of features\n",
        "\n",
        "    Returns:\n",
        "      Torch tensor of model predictions\n",
        "    \"\"\"\n",
        "\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "OUO0qcYOeRw1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance\n",
        "net = LogisticReg(input_size = X_train.shape[1], output_size = nc).to(device)\n",
        "# Create a cross entropy loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Adam optimizer\n",
        "adam_optimizer = torch.optim.Adam(net.parameters(), lr= learning_rate)"
      ],
      "metadata": {
        "id": "_-cpN-tOgGLj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main loop\n",
        "main(net, adam_optimizer, criterion, epochs, iters, X_train, X_val, y_train, y_val, bsz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngull-MBgdwQ",
        "outputId": "f7d95a26-963b-45db-cd93-3bc151bfb682"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 train loss: 6.84 Validation loss: 3.38 train accuracy: 78.98 validation accuracy: 86.40\n",
            "Epoch: 5 train loss: 2.47 Validation loss: 2.51 train accuracy: 88.19 validation accuracy: 88.89\n",
            "Epoch: 10 train loss: 2.27 Validation loss: 2.58 train accuracy: 89.23 validation accuracy: 88.55\n",
            "Epoch: 15 train loss: 2.31 Validation loss: 2.64 train accuracy: 89.02 validation accuracy: 89.21\n",
            "Epoch: 20 train loss: 2.29 Validation loss: 3.28 train accuracy: 89.25 validation accuracy: 86.54\n",
            "Epoch: 24 train loss: 2.15 Validation loss: 2.97 train accuracy: 89.77 validation accuracy: 88.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "6yXQvgsMmm_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"\n",
        "  Convolutional Neural Network model\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initialise parameters of CNN\n",
        "\n",
        "    Args:\n",
        "      Nothing\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    \n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.AdaptiveAvgPool2d((1,1)),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=64, out_features=128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=128, out_features=10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of CNN\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Output after passing through CNN\n",
        "    \"\"\"\n",
        "    return self.layers(x)\n",
        "\n",
        "  def layer_summary(self, X_shape, device):\n",
        "    \"\"\"\n",
        "    Prints the output shape at each layer\n",
        "\n",
        "    Args:\n",
        "      X_shape: torch.tensor\n",
        "        Shape of X_train\n",
        "      device: string\n",
        "        GPU/CUDA if available, CPU otherwise\n",
        "    \"\"\"\n",
        "    X=torch.randn(*X_shape).to(device)\n",
        "    for layer in self.layers:\n",
        "      X=layer(X)\n",
        "      print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "id": "fY_lyNmbqHzC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "cnn = CNN().to(device)\n",
        "# Output of each layer\n",
        "cnn.layer_summary((128,1,28,28), device)\n",
        "# Adam optimizer\n",
        "adam_optimizer = torch.optim.Adam(cnn.parameters(), lr= learning_rate)\n",
        "# Create a cross entropy loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "x407rExKi-NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d40b33b-f535-4848-81c3-1a7d64301c8d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([128, 32, 26, 26])\n",
            "ReLU output shape:\t torch.Size([128, 32, 26, 26])\n",
            "MaxPool2d output shape:\t torch.Size([128, 32, 13, 13])\n",
            "Conv2d output shape:\t torch.Size([128, 64, 11, 11])\n",
            "ReLU output shape:\t torch.Size([128, 64, 11, 11])\n",
            "MaxPool2d output shape:\t torch.Size([128, 64, 5, 5])\n",
            "AdaptiveAvgPool2d output shape:\t torch.Size([128, 64, 1, 1])\n",
            "Flatten output shape:\t torch.Size([128, 64])\n",
            "Linear output shape:\t torch.Size([128, 128])\n",
            "ReLU output shape:\t torch.Size([128, 128])\n",
            "Linear output shape:\t torch.Size([128, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main loop\n",
        "main(cnn, adam_optimizer, criterion, epochs, iters, X_train.reshape(-1, 1, 28, 28), X_val.reshape(-1, 1, 28, 28), y_train, y_val, bsz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696d2c73-72db-4f1b-ea83-048834d42f11",
        "id": "m13ld3RSjVWv"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 train loss: 1.63 Validation loss: 0.54 train accuracy: 55.62 validation accuracy: 85.58\n",
            "Epoch: 5 train loss: 0.17 Validation loss: 0.18 train accuracy: 94.80 validation accuracy: 94.46\n",
            "Epoch: 10 train loss: 0.12 Validation loss: 0.11 train accuracy: 96.24 validation accuracy: 96.52\n",
            "Epoch: 15 train loss: 0.11 Validation loss: 0.13 train accuracy: 96.59 validation accuracy: 95.79\n",
            "Epoch: 20 train loss: 0.09 Validation loss: 0.09 train accuracy: 97.01 validation accuracy: 97.36\n",
            "Epoch: 24 train loss: 0.06 Validation loss: 0.07 train accuracy: 98.21 validation accuracy: 97.64\n"
          ]
        }
      ]
    }
  ]
}